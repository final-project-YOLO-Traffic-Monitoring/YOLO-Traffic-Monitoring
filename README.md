# YOLO-Traffic-Monitoring
Traffic monitoring using YOLO for vehicle classification and video processing

# YOLO Traffic Monitoring Project

## Overview
This project focuses on traffic monitoring and vehicle classification using YOLOv8. The application processes videos by extracting frames, classifying them, and creating a new video with labeled frames. The project supports training a custom YOLOv8 model on your dataset and running the trained model for inference on images or videos.

## Features
- **Custom YOLOv8 Training**:
  - Train your model either locally using PyCharm or on Google Colab with GPU for faster training.
- **Video to Frames Conversion**:
  - Extract frames from a video for preprocessing or inference.
- **Inference Application**:
  - Run the trained YOLOv8 model to classify and label images or videos.

---

## Getting Started
To use this project, follow these steps:

### 1. Setting Up the Environment
- **Option 1**: Train and run locally using PyCharm.
  - Refer to the setup guide: `docs/setup_guide_pycharm.md`.
- **Option 2**: Train the model on Google Colab for faster processing.
  - Refer to the training guide: `docs/colab_training.md`.
  - Alternatively, use the provided script: `scripts/train_yolov8_colab.py`.

---

### 2. Training the YOLOv8 Model
- **Locally**:
  - Follow the instructions in the PyCharm setup guide to train YOLOv8 on your local machine.
- **On Google Colab**:
  - Use the `train_yolov8_colab.py` script or follow the Colab training guide for quick training on GPU.

After training, download the trained weights file (`best.pt`) from the `runs/train/weights` directory. Save it to your local project directory under `models/`.

---

### 3. Running the Application
Once training is complete and the weights are downloaded, you can run the inference application to classify and label images or videos.

- **Video to Frames Conversion**:
  - Use the provided script to extract frames from a video. This step is necessary for preprocessing or frame-by-frame inference.

- **Running Inference**:
  - Provide the application with images or a video, and it will output labeled images or a new video with labels.

Refer to the usage guide: `docs/app_guide.md` for detailed instructions.

---

## File Structure
Here's an overview of the project structure:

``` 
YOLO-Traffic-Monitoring/
├── README.md                # Main project documentation
├── docs/                    # Documentation for setup and usage
│   ├── setup_guide_pycharm.md  # Guide for setting up and training locally
│   ├── colab_training.md       # Guide for training on Google Colab
│   ├── app_guide.md            # Guide for using the application
├── scripts/                 # Python scripts for training and inference
│   ├── train_yolov8_colab.py   # Training script for Google Colab
│   ├── video_to_frames.py      # Script to convert video into frames
│   ├── run_inference.py        # Script for running YOLOv8 inference
├── models/                  # Directory for storing trained model weights
│   ├── best.pt                 # YOLOv8 custom-trained weights
├── data/                    # Example datasets and configurations
│   ├── example_images/         # Example input images for testing
│   ├── example_video.mp4       # Example input video for testing
│   ├── data.yaml               # Dataset configuration file
├── results/                 # Outputs generated by the application
│   ├── labeled_images/         # Directory containing labeled images
│   ├── labeled_video.mp4       # Final labeled video
├── requirements.txt         # List of dependencies to install

```

## Dataset
The dataset can be downloaded from [Google Drive](https://drive.google.com/drive/folders/10ZyQEE5SAZgdqdWgBbnXNbo4nRssAtgr).

## src
- `train_yolov8_colab.py`: Script to train YOLOv8 on Google Colab.
  - Clone the repository, set up the environment, and train the model using your custom dataset.


## Documentation
- [Setup Guide](docs/setup_guide.md)
- [User Guide](docs/user_guide.md)
