# YOLO Traffic Monitoring Project

## Overview
This project focuses on traffic monitoring and vehicle classification using YOLOv8. The application processes videos by extracting frames, classifying them, and creating a new video with labeled frames. The project supports training a custom YOLOv8 model on your dataset and running the trained model for inference on images or videos.

## Features
- **Custom YOLOv8 Training**:
  - Train your model either locally using PyCharm or on Google Colab with GPU for faster training.
- **Video to Frames Conversion**:
  - Extract frames from a video for preprocessing or inference.
- **Inference Application**:
  - Run the trained YOLOv8 model to classify and label images or videos.

---

## Getting Started
To use this project, follow these steps:

### 1. Setting Up the Environment
- **Option 1**: Train and run locally using PyCharm.
  - Refer to the setup guide: `docs/setup_guide_pycharm.md`.
- **Option 2**: Train the model on Google Colab for faster processing.
  - Refer to the training guide: `docs/colab_training.md`.
  - Alternatively, use the provided script: `src/train_yolov8_colab.py`.

---

### 2. Training the YOLOv8 Model
- **Locally**:
  - Follow the instructions in the PyCharm setup guide to train YOLOv8 on your local machine.
- **On Google Colab**:
  - Use the `train_yolov8_colab.py` script or follow the Colab training guide for quick training on GPU.

After training, download the trained weights file (`best.pt`) from the `runs/train/weights` directory. Save it to your local project directory under `models/`.

---

### 3. Running the Application
Once training is complete and the weights are downloaded, you can run the inference application to classify and label images or videos.

- **Video to Frames Conversion**:
  - Use the provided script to extract frames from a video. This step is necessary for preprocessing or frame-by-frame inference.

- **Running Inference**:
  - Provide the application with images or a video, and it will output labeled images or a new video with labels.

Refer to the usage guide: `docs/app_guide.md` for detailed instructions.

---

## File Structure
Here's an overview of the project structure:

``` 
YOLO-Traffic-Monitoring/
├── README.md                # Main project documentation
├── docs/                    # Documentation for setup and usage
│   ├── setup_guide_pycharm.md  # Guide for setting up and training locally
│   ├── colab_training.md       # Guide for training on Google Colab
│   ├── app_guide.md            # Guide for using the application
├── src/                 # Python scripts for training and inference
│   ├── train_yolov8_colab.py   # Training script for Google Colab
│   ├── video_classification_app.py      # Script to convert video into frames
│   ├── app.py        # Script for running YOLOv8 inference in the app
├── models/                  # Directory for storing trained model weights
│   ├── best.pt                 # YOLOv8 custom-trained weights
├── data/                    # Example datasets and configurations
│   ├── example_video.md       # Example input video for testing
│   ├── data.yaml               # Dataset configuration file
├── results/                 # Outputs generated by the application
│   ├── train result/         # Directory containing the train result
│   ├── labeled_video.md       # Final labeled video

```

## Dataset
The dataset can be downloaded from [Google Drive](https://drive.google.com/drive/folders/10ZyQEE5SAZgdqdWgBbnXNbo4nRssAtgr).

## src
This directory contains the main scripts used in the project.

- `train_yolov8_colab.py`: Script to train YOLOv8 on Google Colab.
  - This script clones the YOLOv8 repository, installs the necessary dependencies, and prepares the environment.
  - It mounts Google Drive to access your dataset, configures the dataset using a `data.yaml` file, and trains the YOLOv8 model.
  - After training, the trained model weights (`best.pt`) can be downloaded for use in the application.

- `app.py`: Main application script for running inference on images and videos.
  - Takes an input image or video and applies the trained YOLOv8 model to classify and label objects.
  - Outputs labeled images or a labeled video saved in the `results/` directory.
  - Includes parameters for customizing input and output paths, as well as adjusting detection confidence thresholds.

- `video_classification_app.py`: Script to process and classify video frames using the trained YOLOv8 model.
  - Converts input videos into frames for frame-by-frame classification.
  - Processes each frame using the model, labels detected objects, and recombines the frames into a labeled video.

